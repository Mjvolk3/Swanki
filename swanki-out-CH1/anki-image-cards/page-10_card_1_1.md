    
## How does the order of polynomial $M$ affect the fitting of the data set shown?

![](https://cdn.mathpix.com/cropped/2024_05_18_a0676cf8759377514923g-1.jpg?height=977&width=1512&top_left_y=203&top_left_x=148)

%

Higher-order polynomials can fit the data points more precisely but may lead to overfitting, where the model captures noise rather than the underlying pattern. For instance:
- $M=0$: Fits as a horizontal line (constant), underfits.
- $M=1$: Fits as a straight line, better but still underfits.
- $M=3$: Fits more accurately and reasonably well.
- $M=9$: Fits all data points exactly but oscillates wildly, showing overfitting.

- #machine-learning.overfitting, #polynomial-regression, #data-fitting 

## What issue is demonstrated by the ninth-order polynomial in the context of polynomial fitting?

![](https://cdn.mathpix.com/cropped/2024_05_18_a0676cf8759377514923g-1.jpg?height=427&width=706&top_left_y=214&top_left_x=155)

%

The ninth-order polynomial demonstrates the problem of overfitting, where the model fits the training data perfectly but leads to high variance and oscillations, failing to generalize well to unseen data.

- #machine-learning.overfitting, #polynomial-regression, #model-complexity