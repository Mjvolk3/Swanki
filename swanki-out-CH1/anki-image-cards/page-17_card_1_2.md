## First Card

![](https://cdn.mathpix.com/cropped/2024_05_18_e3e9e09029c9f9357332g-1.jpg?height=338&width=379&top_left_y=212&top_left_x=1281)

How is a single neuron's function mathematically represented in a neural network diagram?

%

A single neuron's function in a neural network diagram can be mathematically represented as:

$$
\begin{aligned}
a & =\sum_{i=1}^{M} w_{i} x_{i} \\
y & =f(a)
\end{aligned}
$$

where $x_{1}, \ldots, x_{M}$ are the inputs, $w_{1}, \ldots, w_{M}$ are the weights, $a$ is the pre-activation, and $f(a)$ is the activation function producing the output $y$.

- #neural-networks, #mathematics, #artificial-intelligence

## Second Card

![](https://cdn.mathpix.com/cropped/2024_05_18_e3e9e09029c9f9357332g-1.jpg?height=338&width=379&top_left_y=212&top_left_x=1281)

Explain the analogy between the polynomial function (1.1) and the neural network model.

%

The polynomial function (1.1) can be viewed as a specific instance of the neural network model where the inputs $x_{i}$ are powers of a single variable $x$, and the activation function $f(a)=a$ is the identity function. Therefore, the neural network model generalizes the polynomial function by allowing for different inputs $x_{1}, x_{2}, \ldots, x_{M}$ and a nonlinear activation function $f(\cdot)$.

- #neural-networks, #polynomials, #mathematics