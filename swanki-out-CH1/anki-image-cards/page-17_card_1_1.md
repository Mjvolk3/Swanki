### Anki Card 1

    How is the pre-activation ($a$) and activation ($y$) defined in a simple neural network?

    ![](https://cdn.mathpix.com/cropped/2024_05_18_e3e9e09029c9f9357332g-1.jpg?height=338&width=379&top_left_y=212&top_left_x=1281)
    
    %
    
    The pre-activation $a$ and activation $y$ in a simple neural network are defined mathematically as:

    $$
    \begin{aligned}
    a & =\sum_{i=1}^{M} w_{i} x_{i} \\
    y & =f(a)
    \end{aligned}
    $$

    Here, $x_{1}, \ldots, x_{M}$ are the inputs, $w_{1}, \ldots, w_{M}$ are the weights, $a$ is the pre-activation, $f(\cdot)$ is the activation function, and $y$ is the activation output.

    - #machine-learning, #neural-networks, #pre-activation-activation

### Anki Card 2

    What constitutes the inputs ($x_i$) and weights ($w_i$) in the context of the simple neural network depicted in Figure 1.13?

    ![](https://cdn.mathpix.com/cropped/2024_05_18_e3e9e09029c9f9357332g-1.jpg?height=338&width=379&top_left_y=212&top_left_x=1281)
    
    %
    
    In the context of the simple neural network depicted in Figure 1.13, the inputs $x_{1}, \ldots, x_{M}$ represent the activities of other neurons that send connections to the neuron of interest. The weights $w_{1}, \ldots, $w_{M}$ are continuous variables that represent the strengths of the associated synapses.

    - #machine-learning, #neural-networks, #neuron-inputs-weights