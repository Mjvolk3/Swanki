#### What does Figure 1.10 illustrate in the context of model selection?

![](https://cdn.mathpix.com/cropped/2024_05_18_990fac6c15f219991e40g-1.jpg?height=440&width=884&top_left_y=212&top_left_x=779)

%

Figure 1.10 illustrates the graph of the root-mean-square error ($E_{RMS}$) versus $\ln \lambda$ for an $M=9$ polynomial. It shows the change in $E_{RMS}$ for both the training set (red curve) and test set (blue curve) as the regularization parameter $\lambda$ varies. The curves demonstrate that both underfitting and overfitting can be managed by choosing appropriate model hyperparameters, thus achieving a balance between fitting the training data and generalizing to unseen data.

- #machine-learning, #model-selection, #hyperparameters