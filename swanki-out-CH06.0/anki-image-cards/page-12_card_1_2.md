## Example Card 1: Description of Training Data

![](https://cdn.mathpix.com/cropped/2024_05_26_53b5c38c9dec90db1928g-1.jpg?height=401&width=491&top_left_y=222&top_left_x=624)

What are the characteristics of the data points used to train the two-layer network shown in the image?

%

The data points, represented by blue dots, are $N=50$ samples uniformly distributed over the interval $(-1, 1)$ in $x$. The corresponding values of the function $f(x)$ are evaluated for these data points and used in training the network.

- #machine-learning, #neural-networks, #training-data

## Example Card 2: Universal Approximation Property

![](https://cdn.mathpix.com/cropped/2024_05_26_53b5c38c9dec90db1928g-1.jpg?height=401&width=491&top_left_y=222&top_left_x=624)

What is the universal approximation theorem in the context of neural networks?

%

The universal approximation theorem states that a two-layer feed-forward network, for a wide range of activation functions, can approximate any continuous function defined over a subset of $ \mathbb{R}^{D} $ to an arbitrary degree of accuracy. This implies that neural networks are capable of representing any finite-dimensional discrete space function to another and are thus termed universal approximators.

- #machine-learning, #neural-networks, #approximation-theorem