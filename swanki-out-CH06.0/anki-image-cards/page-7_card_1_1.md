## Explain the concept illustrated by the two-dimensional scatter plot with two classes separated by a dashed diagonal line in Figure 6.6(a).

![](https://cdn.mathpix.com/cropped/2024_05_26_0971150439f155ba27cfg-1.jpg?height=508&width=515&top_left_y=215&top_left_x=304)

%

Figure 6.6(a) illustrates a data set in two dimensions $\left(x_1, x_2\right)$. Data points from two distinct classes, depicted using green and red circles, can be separated by a linear decision surface (dashed diagonal line). This graphical representation demonstrates linear separability in a two-dimensional feature space, indicating that a linear classifier can accurately classify the data points based on the values of the features $x_1$ and $x_2$.

- tags: data-science, machine-learning.linear-classification, visualization

---

## What happens to the classes' separability if only the variable $x_1$ is measured, as shown in Figure 6.6(b)?

![](https://cdn.mathpix.com/cropped/2024_05_26_0971150439f155ba27cfg-1.jpg?height=508&width=515&top_left_y=215&top_left_x=304)

%

In Figure 6.6(b), if only the variable $x_1$ is measured, the classes are no longer separable. The dimensionality reduction from two dimensions $\left(x_1, x_2\right)$ to one dimension $\left(x_1\right)$ removes the ability to distinguish between the two classes using a linear decision surface. This implies that critical information contained in the $x_2$ variable is lost, making linear classification infeasible.

- tags: data-science, machine-learning.linear-classification, visualization