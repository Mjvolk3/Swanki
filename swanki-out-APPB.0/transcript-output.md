**Appendix B: Calculus of Variations**

Let’s start by thinking of a function \( y(x) \). This function acts as an operator that takes any input value \( x \) and returns an output value \( y \). Now, imagine we have a functional \( F[y] \). A functional is a bit more complex—it’s an operator that takes a function \( y(x) \) as its input and returns a single output value \( F \). For example, consider the length of a curve in a two-dimensional plane. The path of this curve can be defined by a function, and the length of this curve is a functional because it takes the function defining the path as input and returns a scalar value representing the curve's length. In machine learning, a familiar functional is the entropy of a continuous variable \( x \). Given a probability density function \( p(x) \), the entropy \( H[p] \) returns a scalar value representing the entropy of \( x \) under that density.

A typical problem in calculus is finding the value of \( x \) that maximizes or minimizes a function \( y(x) \). In the calculus of variations, the objective is similar, but instead of finding a specific value, we seek a function \( y(x) \) that maximizes or minimizes a functional \( F[y] \). Essentially, out of all possible functions \( y(x) \), we aim to find the one for which the functional \( F[y] \) reaches its maximum or minimum value. This powerful mathematical technique can, for example, demonstrate that the shortest path between two points is a straight line or that the maximum entropy distribution is a Gaussian distribution.

Now, let’s delve into how we understand changes in functionals. If you’re familiar with ordinary calculus, you know that we can evaluate a derivative of \( y \) with respect to \( x \) by making a small change \( \epsilon \) to \( x \) and expanding in powers of \( \epsilon \). For instance, \( y(x + \epsilon) \) can be approximated as \( y(x) + (\mathrm{d}y / \mathrm{d} x) \epsilon \) plus higher-order terms. Similarly, for a function of several variables, \( y(x_1, \ldots, x_D) \), the partial derivatives can be defined by how \( y \) changes with small perturbations in each variable. When we extend this to functionals, we consider how much a functional \( F[y] \) changes when we make a small change \( \epsilon \eta(x) \) to the function \( y(x) \), where \( \eta(x) \) is an arbitrary function of \( x \).

The concept of functional derivatives comes into play when we analyze these changes. For a functional \( F[y] \), we denote its functional derivative with respect to \( y(x) \) as \( \delta F / \delta y(x) \). This derivative captures how \( F[y] \) changes in response to small variations in \( y(x) \). Mathematically, this is expressed by considering the change in \( F[y(x) + \epsilon \eta(x)] \), which can be approximated as \( F[y(x)] + \epsilon \int (\delta F / \delta y(x)) \eta(x) \, \mathrm{d} x \) plus higher-order terms. For the functional to be stationary, the integral involving the functional derivative must vanish for any choice of \( \eta(x) \), leading us to the conclusion that the functional derivative itself must be zero.

To make this more concrete, let’s look at a functional defined by an integral over some function \( G(y, y', x) \), where \( y' \) denotes the derivative of \( y \) with respect to \( x \). The functional can be written as \( F[y] = \int G(y(x), y'(x), x) \, \mathrm{d} x \). When we introduce a small variation \( \epsilon \eta(x) \) to \( y(x) \), the change in the functional can be expressed as an integral involving the partial derivatives of \( G \). By integrating by parts and using the fact that \( \eta(x) \) vanishes at the boundaries, we can isolate the term involving \( \eta(x) \) and identify the functional derivative. Setting this derivative to zero yields the Euler-Lagrange equations, which are fundamental in finding the function \( y(x) \) that maximizes or minimizes the functional.

For example, if \( G \) is given by \( y(x)^2 + (y'(x))^2 \), the Euler-Lagrange equation simplifies to a second-order differential equation, \( y(x) - (\mathrm{d}^2 y / \mathrm{d} x^2) = 0 \). Solving this differential equation with appropriate boundary conditions gives us the function \( y(x) \) that optimizes the functional. This framework can be extended to more complex scenarios, including cases where the functional depends on a probability distribution, requiring the use of Lagrange multipliers to handle constraints.

In summary, the calculus of variations is a powerful tool that extends the principles of calculus to functionals. It enables us to find optimal functions that maximize or minimize a given criterion, with applications ranging from physics to machine learning.