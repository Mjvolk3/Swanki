![](https://cdn.mathpix.com/cropped/2024_06_13_57844719c558b7c67b96g-1.jpg?height=535&width=1276&top_left_y=207&top_left_x=380)

Figure 2.16: Illustration of the effect of outliers on fitting Gaussian, Student and Laplace distributions. (a) No outliers (the Gaussian and Student curves are on top of each other). (b) With outliers. We see that the Gaussian is more affected by outliers than the Student and Laplace distributions. Adapted from Figure 2.16 of [Bis06]. Generated by robust_pdf_plot.ipynb.

We see that the probability density decays as a polynomial function of the squared distance from the center, as opposed to an exponential function, so there is more probability mass in the tail than with a Gaussian distribution, as shown in Figure 2.15. We say that the Student distribution has heavy tails, which makes it robust to outliers.

To illustrate the robustness of the Student distribution, consider Figure 2.16. On the left, we show a Gaussian and a Student distribution fit to some data with no outliers. On the right, we add some outliers. We see that the Gaussian is affected a lot, whereas the Student hardly changes. We discuss how to use the Student distribution for robust linear regression in Section 11.6.2.

For later reference, we note that the Student distribution has the following properties:

$$
\text { mean }=\mu, \text { mode }=\mu, \operatorname{var}=\frac{\nu \sigma^{2}}{(\nu-2)}
$$

The mean is only defined if $\nu>1$. The variance is only defined if $\nu>2$. For $\nu \gg 5$, the Student distribution rapidly approaches a Gaussian distribution and loses its robustness properties. It is common to use $\nu=4$, which gives good performance in a range of problems [LLT89].

\title{
2.7.2 Cauchy distribution
}

If $\nu=1$, the Student distribution is known as the Cauchy or Lorentz distribution. Its pdf is defined by

$$
\mathcal{C}(x \mid \mu, \gamma)=\frac{1}{\gamma \pi}\left[1+\left(\frac{x-\mu}{\gamma}\right)^{2}\right]^{-1}
$$

This distribution has very heavy tails compared to a Gaussian. For example, $95 \%$ of the values from a standard normal are between -1.96 and 1.96, but for a standard Cauchy they are between -12.7 and 12.7. In fact the tails are so heavy that the integral that defines the mean does not converge.

Draft of "Probabilistic Machine Learning: An Introduction". August 8, 2022