## Geometric Interpretation of Least Squares Solution in N-dimensional Space

![](https://cdn.mathpix.com/cropped/2024_05_26_4d03a03b9a49734662f9g-1.jpg?height=367&width=543&top_left_y=217&top_left_x=1106)

What does the blue vector 'y', the green vector 't', and the subspace 'S' represent in the geometrical interpretation of the least squares solution?

%

In the geometrical interpretation of the least squares solution:
- The blue vector 'y' represents the least squares solution, which is the orthogonal projection of the data vector $\mathbf{t}$ onto the subspace 'S'.
- The green vector 't' represents the vector of target values in the $N$-dimensional space.
- The subspace 'S' is spanned by the basis functions $\phi_j(\mathbf{x})$, illustrated by the vectors $\varphi_1$ and $\varphi_2$ within the diagram.

- #linear-algebra, #least-squares, #machine-learning.geometry

---

## Basis Functions in Least Squares Solved Geometrically

![](https://cdn.mathpix.com/cropped/2024_05_26_4d03a03b9a49734662f9g-1.jpg?height=367&width=543&top_left_y=217&top_left_x=1106)

How are the basis functions $\phi_{j}(\mathbf{x})$ represented in the N-dimensional space for the geometrical interpretation of least squares?

%

For the geometrical interpretation of least squares, each basis function $\phi_{j}(\mathbf{x})$ evaluated at the $N$ data points is represented as a vector $\varphi_{j}$ in the $N$-dimensional space. These vectors $\varphi_{j}$ correspond to the $j$-th column of the matrix $\boldsymbol{\Phi}$.

- #linear-algebra, #least-squares, #machine-learning.basis-functions